{"version":3,"sources":["webpack:///./src/static/face-loading.gif","webpack:///./node_modules/@babel/runtime/helpers/esm/typeof.js","webpack:///./src/pages/LoadingInit.vue?52ea","webpack:///src/pages/LoadingInit.vue","webpack:///./src/pages/LoadingInit.vue?d1a3","webpack:///./src/pages/LoadingInit.vue","webpack:///./src/static/myface.jpg"],"names":["module","exports","_typeof","obj","Symbol","iterator","constructor","prototype","render","_vm","this","_h","$createElement","_self","_c","_m","staticRenderFns","staticClass","staticStyle","attrs","_v","console","log","window","device","platform","MODEL_URL","component"],"mappings":"uGAAAA,EAAOC,QAAU,IAA0B,iC,kICA5B,SAASC,EAAQC,GAa9B,OATED,EADoB,oBAAXE,QAAoD,kBAApBA,OAAOC,SACtC,SAAiBF,GACzB,cAAcA,GAGN,SAAiBA,GACzB,OAAOA,GAAyB,oBAAXC,QAAyBD,EAAIG,cAAgBF,QAAUD,IAAQC,OAAOG,UAAY,gBAAkBJ,GAItHD,EAAQC,K,2CCbjB,IAAIK,EAAS,WAAa,IAAIC,EAAIC,KAASC,EAAGF,EAAIG,eAAsBH,EAAII,MAAMC,GAAO,OAAOL,EAAIM,GAAG,IACnGC,EAAkB,CAAC,WAAa,IAAIP,EAAIC,KAASC,EAAGF,EAAIG,eAAmBE,EAAGL,EAAII,MAAMC,IAAIH,EAAG,OAAOG,EAAG,MAAM,CAACG,YAAY,YAAY,CAACH,EAAG,MAAM,CAACG,YAAY,wEAAwEC,YAAY,CAAC,OAAS,UAAU,CAACJ,EAAG,MAAM,CAACG,YAAY,OAAO,CAACH,EAAG,MAAM,CAACG,YAAY,UAAU,CAACH,EAAG,MAAM,CAACK,MAAM,CAAC,IAAM,EAAQ,QAA6B,IAAM,QAAQL,EAAG,MAAM,CAACG,YAAY,UAAU,CAACH,EAAG,MAAM,CAACG,YAAY,mGAAmGC,YAAY,CAAC,MAAQ,SAAS,CAACT,EAAIW,GAAG,iDAAiDN,EAAG,MAAM,CAACI,YAAY,CAAC,SAAW,WAAW,UAAU,OAAO,IAAM,YAAY,KAAO,WAAWC,MAAM,CAAC,IAAM,EAAQ,QAAuB,GAAK,SAAS,IAAM,U,oVCmBxyB,yCAgBA,GACE,QADF,WAEI,IAAJ,OACA,6EACM,SAAN,2CACQ,EAAR,0BAGM,EAAN,wBAGE,OAAF,MACE,QAAF,CACI,qBADJ,WACM,IAAN,OAAM,OAAN,qDAAQ,IAAR,EAAQ,OAAR,6EAEA,2CAEA,6EAJA,oBAKgBE,QAAQC,IAAI,SAA5B,QACgBD,QAAQC,IAAIC,OAAOC,OAAOC,UAC1C,mCAPA,wBASgB,EAChB,uDACgB,QAAhB,gBACgB,EAAhB,oBACkB,SAAlB,YAAoB,OACpB,yBACsB,OAAtB,0BACA,GACA,YACwB,EAAxB,MACA,YAC0B,IAA1B,iBAEA,IACA,cACA,WACA,MACA,YAC4B,EAA5B,qBAC8B,EAA9B,cAE4B,EAA5B,gBAE4B,EAA5B,qBAC8B,EAA9B,8BAG4B,EAA5B,yBAGA,WAC0B,GAA1B,SAIA,WACwB,GAAxB,UAIkB,OAAlB,kBACkB,MAAlB,iBACkB,UAAlB,UACkB,MAAlB,iBACkB,oBAAlB,WAAoB,OAApB,kCACkB,mBAAlB,WAAoB,OAApB,iCAtDA,UA6DA,yCA7DA,yBA8DA,6CA9DA,yBA+DA,4CA/DA,yBAiEA,4CAjEA,uCAqEgBC,EAAY,UACZL,QAAQC,IAAI,UAA5B,GAtEA,UA0EA,gCA1EA,yBA2EA,iCA3EA,yBA4EA,8BA5EA,yBA8EA,gCA9EA,QAgFA,+CAEA,qBAlFA,+CAqFI,iBAtFJ,WAuFM,IAAN,OAMM,EAAN,uBAII,oBAjGJ,WAiGM,IAAN,OAAM,OAAN,qDAAQ,IAAR,IAAQ,OAAR,0EACA,IACA,qCAEA,EAGA,wEACA,kBACA,8CACA,2BAVA,gDCjJqV,I,YCOjVK,EAAY,eACd,EACAnB,EACAQ,GACA,EACA,KACA,KACA,MAIa,aAAAW,E,8BClBf3B,EAAOC,QAAU,IAA0B","file":"js/page-LoadingInit.62a283a1.js","sourcesContent":["module.exports = __webpack_public_path__ + \"img/face-loading.e13af414.gif\";","export default function _typeof(obj) {\n  \"@babel/helpers - typeof\";\n\n  if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {\n    _typeof = function _typeof(obj) {\n      return typeof obj;\n    };\n  } else {\n    _typeof = function _typeof(obj) {\n      return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;\n    };\n  }\n\n  return _typeof(obj);\n}","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"bg-black\"},[_c('div',{staticClass:\"d-flex justify-content-center align-items-center shadow-lg rounded-lg\",staticStyle:{\"height\":\"100vh\"}},[_c('div',{staticClass:\"row\"},[_c('div',{staticClass:\"col-12\"},[_c('img',{attrs:{\"src\":require(\"@/static/face-loading.gif\"),\"alt\":\"\"}})]),_c('div',{staticClass:\"col-12\"},[_c('div',{staticClass:\"text-center text-white font-semibold text-lg animate__animated animate__bounce animate__infinite\",staticStyle:{\"width\":\"100%\"}},[_vm._v(\" Loading Face Recognition Engine ... \")])])])]),_c('img',{staticStyle:{\"position\":\"absolute\",\"z-index\":\"-100\",\"top\":\"-100000px\",\"left\":\"10000px\"},attrs:{\"src\":require(\"@/static/myface.jpg\"),\"id\":\"myface\",\"alt\":\"\"}})])}]\n\nexport { render, staticRenderFns }","<template>\r\n    <div class=\"bg-black\">\r\n        <div style=\"height:100vh;\" class=\"d-flex justify-content-center align-items-center shadow-lg rounded-lg\">\r\n            <div class=\"row\">\r\n                <div class=\"col-12\">\r\n                    <img src=\"@/static/face-loading.gif\" alt=\"\">\r\n                </div>\r\n                <div class=\"col-12\">\r\n                    <div style=\"width:100%\" class=\"text-center text-white font-semibold text-lg animate__animated animate__bounce animate__infinite\">\r\n                     Loading Face Recognition Engine ...\r\n                    </div>\r\n                </div>\r\n            </div>\r\n        </div>\r\n        <img src=\"@/static/myface.jpg\" id=\"myface\" alt=\"\" style=\"position:absolute;z-index:-100;top:-100000px;left:10000px;\">\r\n\r\n    </div>\r\n</template>\r\n<script>\r\nimport autophp from '@/plugins/auto';\r\nlet sdb = new autophp('ci','https://ebkm.my.id/');\r\n// import * as H from '@/static/dist/human.esm.js'; // equivalent of import @vladmandic/Human\r\n//  const humanConfig = { // user configuration for human, used to fine-tune behavior\r\n//     modelBasePath: './models2', // models can be loaded directly from cdn as well\r\n//     filter: { enabled: true, equalization: true, flip: false },\r\n//     face: { enabled: true, detector: { rotation: false }, mesh: { enabled: true }, attention: { enabled: false }, iris: { enabled: false }, description: { enabled: false }, emotion: { enabled: false } },\r\n//     body: { enabled: false },\r\n//     hand: { enabled: false },\r\n//     gesture: { enabled: true },\r\n//     object: { enabled: false },\r\n//     segmentation: { enabled: false },\r\n// };\r\n// var human = new H.Human(humanConfig); // create instance of human with overrides from user configuration\r\n// initial face api plugin\r\n// import * as faceapi from \"face-api.js\";\r\nimport * as faceapi from '@vladmandic/face-api';\r\nexport default{\r\n    mounted() {\r\n        let that=this;\r\n        if (typeof cordova == \"object\") {\r\n            document.addEventListener(\"deviceready\", function() {\r\n                that.loadFaceDetectModels();\r\n            });\r\n        }else{\r\n            that.loadFaceDetectModels();\r\n        }\r\n    },\r\n    layout:'app',\r\n    methods: {\r\n        async loadFaceDetectModels(){\r\n            let MODEL_URL;\r\n            sdb.alert(\"Proses load model!\",'bg-red-400');\r\n            // cek apakah device menggunakan android atau web\r\n            if (typeof cordova == \"object\") {\r\n                console.log('device',window)\r\n                console.log(window.device.platform)\r\n                if (window.device.platform === \"Android\") {\r\n                  // jika android maka ambil model/weight melalui local file file://\r\n                    MODEL_URL =\r\n                    window.cordova.file.applicationDirectory + \"www/models/\";\r\n                    console.log('before',faceapi)\r\n                    faceapi.env.monkeyPatch({\r\n                    readFile: filePath =>\r\n                        new Promise(resolve => {\r\n                        window.resolveLocalFileSystemURL(\r\n                            filePath,\r\n                            function(fileEntry) {\r\n                            fileEntry.file(\r\n                                function(file) {\r\n                                var reader = new FileReader();\r\n\r\n                                let fileExtension = filePath\r\n                                    .split(\"?\")[0]\r\n                                    .split(\".\")\r\n                                    .pop();\r\n                                if (fileExtension === \"json\") {\r\n                                    reader.onloadend = function() {\r\n                                    resolve(this.result);\r\n                                    };\r\n                                    reader.readAsText(file);\r\n                                } else {\r\n                                    reader.onloadend = function() {\r\n                                    resolve(new Uint8Array(this.result));\r\n                                    };\r\n\r\n                                    reader.readAsArrayBuffer(file);\r\n                                }\r\n                                },\r\n                                function() {\r\n                                resolve(false);\r\n                                }\r\n                            );\r\n                            },\r\n                            function() {\r\n                            resolve(false);\r\n                            }\r\n                        );\r\n                        }),\r\n                    Canvas: HTMLCanvasElement,\r\n                    Image: HTMLImageElement,\r\n                    ImageData: ImageData,\r\n                    Video: HTMLVideoElement,\r\n                    createCanvasElement: () => document.createElement(\"canvas\"),\r\n                    createImageElement: () => document.createElement(\"img\")\r\n                    });\r\n                    // list model/weight yang digunakan \r\n                    // await faceapi.nets.tinyFaceDetector.loadFromDisk(MODEL_URL); \r\n                    // await faceapi.nets.faceRecognitionNet.loadFromDisk(MODEL_URL);\r\n                    // await faceapi.nets.faceLandmark68TinyNet.loadFromDisk(MODEL_URL);\r\n\r\n                    await faceapi.nets.ssdMobilenetv1.loadFromDisk(MODEL_URL);\r\n                    await faceapi.nets.faceRecognitionNet.loadFromDisk(MODEL_URL)\r\n                    await faceapi.nets.faceLandmark68Net.loadFromDisk(MODEL_URL)\r\n\r\n                    await faceapi.nets.faceExpressionNet.loadFromDisk(MODEL_URL);\r\n                } \r\n            }else {\r\n              // Apabila menggunakan web maka load model/weight melalui static public folder\r\n                MODEL_URL = \"/models\";\r\n                console.log('faceapi',faceapi)\r\n                // await faceapi.loadTinyFaceDetectorModel(MODEL_URL);\r\n                // await faceapi.loadFaceRecognitionModel(MODEL_URL);\r\n                // await faceapi.loadFaceLandmarkTinyModel(MODEL_URL);\r\n                await faceapi.loadSsdMobilenetv1Model(MODEL_URL)\r\n                await faceapi.loadFaceRecognitionModel(MODEL_URL)\r\n                await faceapi.loadFaceLandmarkModel(MODEL_URL)\r\n\r\n                await faceapi.loadFaceExpressionModel(MODEL_URL);\r\n            }\r\n          sdb.alert(\"Berhasil load model!\",'bg-green-400')\r\n          // minta camera permission\r\n          this.permissionCamera();\r\n        },\r\n        // Popup permission camera\r\n        permissionCamera(){\r\n          let that=this;\r\n            // navigator.mediaDevices.getUserMedia({\r\n            //         'video': {\r\n            //             'facingMode': 'environment'\r\n            //         }\r\n            // }).then(async(mediaStream) =>{\r\n              that.prepareFaceDetector();\r\n            // });\r\n        },\r\n        // Prepease webgl untuk mengkonsumsi faceapi tensorflow\r\n        async prepareFaceDetector() {\r\n            let that=this;\r\n            const img = document.getElementById('myface');\r\n            // await human.detect(img);\r\n            const useTinyModel = true;\r\n            //   .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())\r\n            // faceapi.detectSingleFace(img, new faceapi.TinyFaceDetectorOptions({ inputSize: 160 })).withFaceLandmarks(useTinyModel).withFaceDescriptor().run()\r\n            faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor().run()\r\n              .then(res => {\r\n                sdb.alert('success prepearing .. .!','bg-dark')\r\n                that.$router.push('/main')\r\n               \r\n              });\r\n      }\r\n    },\r\n}\r\n</script>","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./LoadingInit.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./LoadingInit.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./LoadingInit.vue?vue&type=template&id=26d5f390&\"\nimport script from \"./LoadingInit.vue?vue&type=script&lang=js&\"\nexport * from \"./LoadingInit.vue?vue&type=script&lang=js&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports","module.exports = __webpack_public_path__ + \"img/myface.9161a6ed.jpg\";"],"sourceRoot":""}